{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent_gradient(initial_w, function, gradient, eta=0.01, threshold=None, iterations=100):\n",
    "    \"\"\"\n",
    "    Función para el cálculo del gradiente descendente\n",
    "    \n",
    "    :param initial_w: Pesos iniciales\n",
    "    :param function: Función a evaluar\n",
    "    :param gradient: Función gradiente a utilizar\n",
    "    :param eta: Valor de la tasa de aprendizaje (por defecto 0.01)\n",
    "    :param threshold: Valor umbral con el que parar (por defecto None)\n",
    "    :param iterations: Número máximo de iteraciones que tiene que hacer el bucle\n",
    "                       (por defecto 100)\n",
    "    \n",
    "    :returns: Devuelve el peso final (w), el número de iteraciones que ha llevado\n",
    "              conseguir llegar hasta éste, un array con todos los w y un array con\n",
    "              los valores de w evaluados en function\n",
    "    \"\"\"\n",
    "    \n",
    "    w = np.copy(initial_w)                  # Se copia initial_w para evitar modificarlo\n",
    "    iter = 0                                # Se inicializan las iteraciones a 0\n",
    "    w_list = []                             # Se inicializa una lista vacía con los valors de w\n",
    "    func_values_list = []                   # Se inicializa una lista vacía con los valors de la función\n",
    "    \n",
    "    w_list.append(w)                        # Añadir valor inicial de w\n",
    "    func_values_list.append(function(*w))   # Añadir valor inicial de w evaluado en function\n",
    "\n",
    "    # Se realiza el cálculo de la gradiente descendente mientras no se superen\n",
    "    # el número máximo de iteraciones.\n",
    "    while iter < iterations:\n",
    "        iter += 1\n",
    "        w = w - eta * gradient(*w)              # Actualización de w con los nuevos valores\n",
    "        \n",
    "        w_list.append(w)                        # Añadir nuevo w\n",
    "        func_values_list.append(function(*w))   # Añadir nueva evaluación de w en function\n",
    "        \n",
    "        # Si se ha especificado un umbral en el que parar y se ha pasado\n",
    "        # se sale del bucle\n",
    "        if threshold and function(*w) < threshold:\n",
    "            break\n",
    "\n",
    "    return w, iter, np.array(w_list), np.array(func_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función E(u,v)\n",
    "def E(u, v):\n",
    "    return (u**2 * np.exp(v) - 2 * v**2 * np.exp(-u))**2\n",
    "\n",
    "# Derivada parcial de E respecto a u\n",
    "def diff_Eu(u, v):\n",
    "    return 2 * (u**2 * np.exp(v) - 2 * v**2 * np.exp(-u)) * (2 * u * np.exp(v) + 2 * v**2 * np.exp(-u))\n",
    "\n",
    "# Derivada parcial de E respecto a v\n",
    "def diff_Ev(u, v):\n",
    "    return 2 * (u**2 * np.exp(v) - 2 * v**2 * np.exp(-u)) * (u**2 * np.exp(v) - 4 * v * np.exp(-u))\n",
    "\n",
    "# Gradiente de E\n",
    "def gradient_E(u, v):\n",
    "    return np.array([diff_Eu(u, v), diff_Ev(u, v)])\n",
    "\n",
    "# Funcion f(x, y)\n",
    "def f(x, y):\n",
    "    return x**2 + 2 * y**2 + 2 * np.sin(2 * np.pi * x) * np.sin(2 * np.pi * y)\n",
    "\n",
    "# Derivada parcial de f respecto a x\n",
    "def diff_fx(x, y):\n",
    "    return 2 * x + 4 * np.pi * np.cos(2 * np.pi * x) * np.sin(2 * np.pi * y)\n",
    "\n",
    "# Derivada parcial de f respecto a y\n",
    "def diff_fy(x, y):\n",
    "    return 4 * y + 4 * np.pi * np.sin(2 * np.pi * x) * np.cos(2 * np.pi * y)\n",
    "\n",
    "# Gradiente de f\n",
    "def gradient_f(x, y):\n",
    "    return np.array([diff_fx(x, y), diff_fy(x, y)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de iteraciones:  33\n",
      "Coordenadas obtenidas: ( 0.6192076784506378 ,  0.9684482690100485 )\n"
     ]
    }
   ],
   "source": [
    "# Se fijan los parámetros que se van a usar en el cómputo de la gradiente descendente\n",
    "# (w inicial, num. iteraciones, valor mínimo)\n",
    "initial_w = np.array([1.0, 1.0])\n",
    "max_iter = 10000000000\n",
    "error = 1e-14\n",
    "\n",
    "w, it, w_array, func_val = descent_gradient(initial_w, E, gradient_E, threshold=error, iterations=max_iter)\n",
    "\n",
    "print ('Numero de iteraciones: ', it)\n",
    "print ('Coordenadas obtenidas: (', w[0], ', ', w[1],')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta = 0.01\n",
      "Coordenadas obtenidas = (0.24380496936478835, -0.23792582148617766)\n",
      "Valor de la función = -1.8200785415471563\n",
      "\n",
      "eta = 0.1\n",
      "Coordenadas obtenidas = (0.10039167365942725, -1.0157510051441512)\n",
      "Valor de la función = 1.9570333596159941\n"
     ]
    }
   ],
   "source": [
    "# Se fijan los parámetros que se van a usar en el cómputo de la gradiente descendente\n",
    "# en los dos casos\n",
    "# w inicial, eta del segundo caso a estudiar y número máximo de iteraciones\n",
    "initial_w = np.array([0.1, 0.1])\n",
    "eta = 0.1\n",
    "max_iter = 50\n",
    "\n",
    "# Primer caso: w_inicial = (0.1, 0.1), eta 0.01, iteraciones = 50\n",
    "w_1, it_1, w_array_1, func_val_1 = descent_gradient(initial_w, f, gradient_f, iterations=max_iter)\n",
    "\n",
    "# Segundo caso: w_inicial = (0.1, 0.1), eta 0.1, iteraciones = 50 \n",
    "w_2, it_2, w_array_2, func_val_2 = descent_gradient(initial_w, f, gradient_f, eta=eta, iterations=max_iter)\n",
    "\n",
    "# Mostrar por pantalla los resultados obtenidos\n",
    "print('eta = 0.01') \n",
    "print('Coordenadas obtenidas = ({}, {})'.format(w_1[0], w_1[1]))\n",
    "print('Valor de la función = {}\\n'.format(func_val_1[-1]))\n",
    "\n",
    "print('eta = 0.1') \n",
    "print('Coordenadas obtenidas = ({}, {})'.format(w_2[0], w_2[1]))\n",
    "print('Valor de la función = {}'.format(func_val_2[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x_0  y_0       x_f       y_f  Valor punto final\n",
      "Punto 1  0.1  0.1  0.243805 -0.237926          -1.820079\n",
      "Punto 2  1.0  1.0  1.218070  0.712812           0.593269\n",
      "Punto 3 -0.5 -0.5 -0.731377 -0.237855          -1.332481\n",
      "Punto 4 -1.0 -1.0 -1.218070 -0.712812           0.593269\n"
     ]
    }
   ],
   "source": [
    "# Se fijan los parámetros que se van a usar en el cómputo de la gradiente descendente\n",
    "# en los dos casos\n",
    "# w inicial de cada caso y número máximo de iteraciones\n",
    "initial_w_1 = np.array([0.1, 0.1])\n",
    "initial_w_2 = np.array([1.0, 1.0])\n",
    "initial_w_3 = np.array([-0.5, -0.5])\n",
    "initial_w_4 = np.array([-1.0, -1.0])\n",
    "max_iter = 50\n",
    "\n",
    "# Cálculo del gradiente descendente para cada caso\n",
    "w_1, it_1, w_array_1, func_val_1 = descent_gradient(initial_w_1, f, gradient_f, iterations=max_iter)\n",
    "w_2, it_2, w_array_2, func_val_2 = descent_gradient(initial_w_2, f, gradient_f, iterations=max_iter)\n",
    "w_3, it_3, w_array_3, func_val_3 = descent_gradient(initial_w_3, f, gradient_f, iterations=max_iter)\n",
    "w_4, it_4, w_array_4, func_val_4 = descent_gradient(initial_w_4, f, gradient_f, iterations=max_iter)\n",
    "\n",
    "# Mostrar por pantalla los resultados obtenidos usando pandas\n",
    "# Crear una lista con los nombres de las columnas\n",
    "column_header = ['x_0', 'y_0', 'x_f', 'y_f', 'Valor punto final']\n",
    "row_header = ['Punto 1', 'Punto 2', 'Punto 3', 'Punto 4']\n",
    "\n",
    "# Crear un array con los valores de cada fila\n",
    "rows = np.array([[initial_w_1[0], initial_w_1[1], w_array_1[-1, 0], w_array_1[-1, 1], func_val_1[-1]],\n",
    "                [initial_w_2[0], initial_w_2[1], w_array_2[-1, 0], w_array_2[-1, 1], func_val_2[-1]],\n",
    "                [initial_w_3[0], initial_w_3[1], w_array_3[-1, 0], w_array_3[-1, 1], func_val_3[-1]],\n",
    "                [initial_w_4[0], initial_w_4[1], w_array_4[-1, 0], w_array_4[-1, 1], func_val_4[-1]]])\n",
    "\n",
    "# Crear un nuevo DataFrame\n",
    "df = pandas.DataFrame(rows, index=row_header, columns=column_header)\n",
    "\n",
    "# Mostrarlo por pantalla\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para calcular el error\n",
    "def Err(x, y, w):\n",
    "    error = np.square(x.dot(w) - y.reshape(-1, 1))  # Calcular el error cuadrático para cada vector de características\n",
    "    error = error.mean()                            # Calcular la media de los errors cuadráticos (matriz con una columna)\n",
    "    \n",
    "    return error\n",
    "\n",
    "# Derivada de la función del error\n",
    "def diff_Err(x,y,w):\n",
    "    d_error = x.dot(w) - y.reshape(-1, 1)           # Calcular producto vectorial de x*w y restarle y\n",
    "    d_error =  2 * np.mean(x * d_error, axis=0)     # Realizar la media del producto escalar de x*error y la media en el eje 0\n",
    "    \n",
    "    d_error = d_error.reshape(-1, 1)                # Cambiar la forma para que tenga 3 filas y 1 columna\n",
    "    \n",
    "    return d_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente Descendente Estocastico\n",
    "def sgd(X, y, eta, M=64, iterations=200):\n",
    "    \"\"\"\n",
    "    Función para calcular el Gradiente Descendente Estocástico.\n",
    "    Selecciona minibatches aleatorios de tamaño M de la muestra original\n",
    "    y ajusta en un número de iteraciones los pesos.\n",
    "    \n",
    "    :param X: Muestra de entrenamiento\n",
    "    :param y: Vector de etiquetas\n",
    "    :param eta: Ratio de aprendizaje\n",
    "    :param M: Tamaño de un minibatch (64 por defecto)\n",
    "    :param iterations: Número máximo de iteraciones\n",
    "    \n",
    "    :return w: Pesos ajustados\n",
    "    \"\"\"\n",
    "    \n",
    "    # Crear un nuevo vector de pesos inicializado a 0, establecer el número de iteraciones\n",
    "    # inicial y obtener el número de elementos (N)\n",
    "    w = np.zeros((3, 1), np.float64)\n",
    "    N = X.shape[0]\n",
    "    iter = 0\n",
    "    \n",
    "    # Mientras el número de iteraciones sea menor al máximo, obtener un minibatch\n",
    "    # de tamaño M con valores aleatorios de X y ajustar los pesos con estos valores\n",
    "    while iter < iterations:\n",
    "        iter += 1\n",
    "        \n",
    "        # Escoger valores aleatorios de índices sin repeticiones y obtener los elementos\n",
    "        index = np.random.choice(N, M, replace=False)\n",
    "        minibatch_x = X[index]\n",
    "        minibatch_y = y[index]\n",
    "        \n",
    "        # Actualizar w\n",
    "        w = w - eta * diff_Err(minibatch_x, minibatch_y, w)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudoinversa\n",
    "def pseudoinverse(X, y):\n",
    "    \"\"\"\n",
    "    Función para el cálculo de pesos mediante el algoritmo de la pseudoderivada\n",
    "    \n",
    "    :param X: Matriz que contiene las caracterísiticas\n",
    "    :param y: Matriz que contiene las etiquetas relacionadas a las características\n",
    "    \n",
    "    :returns w: Pesos calculados mediante ecuaciones normales\n",
    "    \"\"\"\n",
    "    \n",
    "    X_transpose = X.transpose()                     # Guardamos la transpuesta de X\n",
    "    y_transpose = y.reshape(-1, 1)                  # Convertimos y en una matriz columna (1 fila con n columnas)\n",
    "    \n",
    "    # Aplicamos el algoritmo para calcular la pseudoinversa\n",
    "    w = np.linalg.inv(X_transpose.dot(X))\n",
    "    w = w.dot(X_transpose)\n",
    "    \n",
    "    # Hacemos el producto de matrices de la pseudoinversa y la matriz columna y\n",
    "    w = w.dot(y_transpose)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
