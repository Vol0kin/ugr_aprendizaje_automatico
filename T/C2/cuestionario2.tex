\documentclass[11pt,a4paper]{article}
\usepackage[spanish,es-nodecimaldot]{babel}	% Utilizar español
\usepackage[utf8]{inputenc}					% Caracteres UTF-8
\usepackage{graphicx}						% Imagenes
\usepackage[hidelinks]{hyperref}			% Poner enlaces sin marcarlos en rojo
\usepackage{fancyhdr}						% Modificar encabezados y pies de pagina
\usepackage{float}							% Insertar figuras
\usepackage[textwidth=390pt]{geometry}		% Anchura de la pagina
\usepackage[nottoc]{tocbibind}				% Referencias (no incluir num pagina indice en Indice)
\usepackage{enumitem}						% Permitir enumerate con distintos simbolos
\usepackage[T1]{fontenc}					% Usar textsc en sections
\usepackage{amsmath}						% Símbolos matemáticos
\usepackage{amssymb}
\usepackage{bbold}

% Comando para poner el nombre de la asignatura
\newcommand{\asignatura}{Aprendizaje Automático}

% Comandos utilies
\newcommand{\answer}{\noindent\textbf{Solución}}
\newcommand{\ein}{E$_{in}$}
\newcommand{\eout}{E$_{out}$}
\newcommand{\addtoc}[1]{\addcontentsline{toc}{section}{#1}}

% Configuracion de encabezados y pies de pagina
\pagestyle{fancy}
\lhead{Vladislav Nikolov Vasilev}
\rhead{\asignatura{}}
\lfoot{Grado en Ingeniería Informática}
\cfoot{}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}		% Linea cabeza de pagina
\renewcommand{\footrulewidth}{0.4pt}		% Linea pie de pagina

\begin{document}
\pagenumbering{gobble}

% Pagina de titulo
\begin{titlepage}

\begin{minipage}{\textwidth}

\centering

\includegraphics[scale=0.5]{img/ugr.png}\\

\textsc{\Large \asignatura{}\\[0.2cm]}
\textsc{GRADO EN INGENIERÍA INFORMÁTICA}\\[1cm]

\noindent\rule[-1ex]{\textwidth}{1pt}\\[1.5ex]
\textsc{{\Huge Trabajo 2\\[0.5ex]}}
\textsc{{\Large Cuestiones de Teoría\\}}
\noindent\rule[-1ex]{\textwidth}{2pt}\\[3.5ex]

\end{minipage}

\vspace{0.5cm}

\begin{minipage}{\textwidth}

\centering

\textbf{Autor}\\ {Vladislav Nikolov Vasilev}\\[2.5ex]
\textbf{Rama}\\ {Computación y Sistemas Inteligentes}\\[2.5ex]
\vspace{0.3cm}

\includegraphics[scale=0.3]{img/etsiit.jpeg}

\vspace{0.7cm}
\textsc{Escuela Técnica Superior de Ingenierías Informática y de Telecomunicación}\\
\vspace{1cm}
\textsc{Curso 2018-2019}
\end{minipage}
\end{titlepage}

\pagenumbering{arabic}
\tableofcontents
\thispagestyle{empty}				% No usar estilo en la pagina de indice

\newpage

\setlength{\parskip}{1em}

\section*{Ejercicio 1}
\addtoc{Ejercicio 1}

\noindent Identificar de forma precisa dos condiciones imprescindibles para que un problema de predicción puede ser aproximado
por inducción desde una muestra de datos. Justificar la respuesta usando los resultados teóricos estudiados.

\answer

Para que un problema de predicción pueda ser aproximado por inducción desde una muestra de datos, necesitamos que se den
las siguientes condiciones:

\begin{itemize}[label=\textbullet]
	\item Que la muestra de datos sea i.i.d. (independiente e identicamente distribuida). Esto significa que los elementos
	de la muestra no se influyen entre sí (independiente) y que cada elemento de la muestra es escogido de la misma
	distribución de probabilidad (idénticamente distribuido).
	\item Que la distribución de probabilidad de los datos de entrenamiento sea la misma que de los de test.
\end{itemize}

Si no se dan estas condiciones, no se puede asegurar una correcta aproximación por inducción. 

En el caso de la primera condición, por ejemplo, si escogemos los datos de forma arbitraria (no i.i.d.) no podríamos decir nada
sobre la población, ya que el análisis probabilístico realizado con la desigualdad de Hoeffding nos dice que, para una muestra
escogida de forma aleatoria, se tiene que:

\[ \mathbb{P}(\mathcal{D}: | \; \text{E}_{in}(h) - \text{E}_{out}(h) \; | \; > \varepsilon) \leq 2e^{-2\varepsilon^2N} \]

\noindent es decir, que escogiendo un tamaño de muestra $N$ lo suficientemente grande y un $\varepsilon$ error razonable,
podemos decir que muy probablemente $\text{\ein{}}(h)$ y $\text{\eout{}}(h)$ disten como mucho entre sí un valor $\epsilon$,
y que por tanto $\text{\ein{}}(h) \approx \text{\eout{}}(h)$. Así que, escogiendo datos de forma arbitraria sería como
trabajar a ciegas, sin ningún tipo de información.

En el caso de la segunda condición, si escogemos datos de entrenamiento de una distribución de probabilidad $\mathsf{P}_1$ 
y luego escogemos datos de test de otra distribución de probabilidad $\mathsf{P}_2$, por mucho que que con nuestro 
algoritmo de aprendizaje hayamos conseguido hacer que $\text{\ein{}} \approx 0$, no podríamos afirmar que
$\text{\ein{}}(h) \approx \text{\eout{}}(h)$, ya que en este caso los datos de entrenamiento y de test provienen de
distribuiciones de probabilidad diferentes, con lo cuál podrían no ser nada parecidos.


\section*{Ejercicio 2}
\addtoc{Ejercicio 2}

\noindent El jefe de investigación de una empresa con mucha experiencia en problemas de predicción de datos tras analizar los
resultados de los muchos algoritmos de aprendizaje usados sobre todos los problemas en los que la empresa ha trabajado a lo
largo de su muy dilatada existencia, decide que para facilitar el mantenimiento del código de la empresa van a seleccionar un
único algoritmo y una única clase de funciones con la que aproximar todas las soluciones a sus problemas presentes y futuros.
¿Considera que dicha decisión es correcta y beneficiará a la empresa? Argumentar la respuesta usando los resultados teóricos
estudiados.

\answer

Se puede considerar que la decisión tomada no es la correcta. Al haber escogido una única clase de funciones y un único
algoritmo se está restringiendo mucho la cantidad de problemas que se pueden resolver. Puede suceder incluso que no resuelva
bien los problemas futuros, ya que la naturaleza de estos no es conocida a priori.

Para intentar justificar por qué no es buena idea restringirse a un único algoritmo, podemos hacer referencia al teorema de
\textbf{No-Free-Lunch}, que dice que para cada algoritmo $\mathcal{A}$ existe una distribución de probabilidad $\mathsf{P}$
en la que dicho algoritmo falla, pero que puede ser aprendida por otro. Por tanto, puede ser que llegue un nuevo problema
cuya distribución de probabilidad sea una en la que el algoritmo que se haya escogido en la empresa falle, y por tanto, la
no obtendrá unos resultados que satisfagan a los clientes, lo cuál se podría traducir en una mala situación para la empresa.

Por otro lado, si se limita la clase de funciones a una que por ejemplo sea muy pequeña, si llega un nuevo problema
puede suceder que la clase de funciones se quede muy corta, y los valores de los errores obtenidos tanto en la muestra de
entrenamiento proporcionada como en la muestra de test sean muy malos, debido a que la función no
tenga la capacidad de explicar correctamente los datos o de generalizar bien. Esto también sería un problema para la empresa,
ya que nadie quiere tener un resultado pésimo que no pueda utilizar luego.

En conclusión, por mucho que en el pasado se hayan usado una serie de algoritmos y clases de funciones, no existe nada
que nos indique que éstos funcionen correctamente para nuevos problemas. Es muy importante explotar el conocimiento específico
del problema para obtener los mejores resultados, y al imponer límites de lo que se va a utilizar
en el problema de aprendizaje se limita la capacidad de decidir qué técnicas utilizar para resolverlo. No existe
ninguna clase de funciones ni algoritmo que resuelvan todos los problemas, y por tanto, para cada problema, hay que realizar
un buen análisis para determinar cuáles serían los más adecuados.

\section*{Ejercicio 3}
\addtoc{Ejercicio 3}

\noindent ¿Que se entiende por una solución PAC a un problema de aprendizaje? Identificar el porqué de la incertidumbre e
imprecisión.

\answer

En el ámbito del aprendizaje, una solución PAC significa que es \textit{Probably Approximately Correct}, 
lo cuál traducido al español vendría a ser algo así como ``correcta probablemente aproximada''.
Veamos qué significa todo esto sobre la desigualdad de Hoeffding aplicada al problema de aprendizaje:

\begin{equation}
\label{eq:hoeffding}
	\mathbb{P}(\mathcal{D}: | \; \text{E}_{in}(h) - \text{E}_{out}(h) \; | \; > \varepsilon) \leq 2e^{-2\varepsilon^2N}
\end{equation}

\begin{itemize}[label=\textbullet]
	\item  La parte de ``probablemente'' hace referencia a una probabilidad. Esto se puede ver en la expresión dada
	por \eqref{eq:hoeffding} como la probabilidad de que algo malo suceda. Este evento malo es que la
	diferencia 	entre los valores de \ein{}$(h)$ y \eout{}$(h)$ sea mayor que un $\varepsilon$ dado, o lo que es lo mismo,
	que los errores disten mucho entre sí. Como en la 	expresión de la parte derecha nos encontramos con un exponencial
	negativo, con los valores adecuados de $\varepsilon$ y $N$ podemos hacer que la probabilidad de que ese mal evento
	suceda sea pequeña, y por tanto, que la probabilidad del caso contrario (que la diferencia entre los valores 
	de \ein{}$(h)$ y \eout{}$(h)$) sea muy probable (tenga una probabilidad más alta).
	\item La parte de ``aproximada'' indica que \ein{}$(h)$ no es exactamente igual que \eout{}$(h)$,
	pero que ambos valores están muy próximos. Esta aproximación viene dada por el valor de $\varepsilon$.
\end{itemize}

La \textbf{incertidumbre} viene dada por la probabilidad. Nunca se puede tener la certeza de que el resultado sea 100\%
correcto, pero se puede afirmar con una alta probabilidad de que así sea (por eso es PAC).
La \textbf{imprecisión}, por otro lado, viene dada por el valor de $\varepsilon$. Es decir, los valores de \ein{}$(h)$ y
\eout{}$(h)$, al estar aprendiendo de una muestra la cuál puede tener un tamaño no lo suficientemente grande o no ser muy
representativa de la población, van a ser diferentes.
Si pudiésemos aprender de toda la población directamente, en ese caso $\varepsilon$ sería 0, ya que los dos errores serían
iguales, pero habría que pagar muchos costes de tiempo, potencia de cómputo y almacenamiento. Por tanto, al estar siempre
aprendiendo de una muestra y no de la población entera nos vamos a encontrar con estos dos problemas.

\section*{Ejercicio 4}
\addtoc{Ejercicio 4}

\noindent Suponga un conjunto de datos $\mathcal{D}$ de 25 ejemplos extraídos de una función desconocida
$f : \mathcal{X} \rightarrow \mathcal{Y}$, donde $\mathcal{X} = \mathbb{R}$ e $\mathcal{Y} = \lbrace -1, +1 \rbrace$.
Para aprender $f$ usamos un conjunto simple de hipótesis $\mathcal{H} = \lbrace h_1 , h_2 \rbrace$ donde $h_1$ es la función
constante igual a $+1$ y $h_2$ la función constante igual a $-1$. Consideramos dos algoritmos de aprendizaje, S(smart) y
C(crazy). S elige la hipótesis que mejor ajusta los datos y C elige deliberadamente la otra hipótesis.

\begin{enumerate}[label=\textit{\alph*})]
	\item ¿Puede S producir una hipótesis que garantice mejor comportamiento que la aleatoria sobre cualquier punto fuera
	de la muestra? Justificar la respuesta.
\end{enumerate}

\answer

No se puede garantizar. Se puede intentar afirmar que, con alta probabilidad, S sea capaz de generalizar mejor que C debido
a que escoge aquella hipótesis que mejor ajusta los datos. Ahora bien, garantizar que pueda tener un mejor comportamiento
sobre cualquier punto fuera de la muestra es algo muy difícil, por no decir casi imposible. Partiendo de que la muestra puede
no representar lo suficientemente bien la población, S puede equivocarse entonces y escoger una hipótesis con la que obtenga
muy buenos resultados en la muestra, pero que al generalizar luego, obtenga un error fuera de la muestra muy elevado, haciendo
por tanto que no sea mejor sobre cualquier punto fuera de la muestra. Además, en el aprendizaje siempre nos encontramos con
incertidumbre, ya que nunca se puede afirmar con toda seguridad que los resultados obtenidos son perfectos y posteriormente
no se cometerán errores al predecir nuevos datos. Y además, no existe ningún algoritmo que nos garantice un mejor aprendizaje
que otro en todos los casos, ya que según el teorema de \textbf{No-Free-Lunch}, existirá una distribución de probabilidad 
$\mathsf{P}$ en la que el algoritmo de aprendizaje $\mathcal{A}$ falle, pero en la que otro obtendrá unos buenos resultados.

\section*{Ejercicio 5}
\addtoc{Ejercicio 5}

\noindent Con el mismo enunciado de la pregunta 4:

\begin{enumerate}[label=\textit{\alph*})]
	\item Asumir desde ahora que todos los ejemplos en $\mathcal{D}$ tienen $y_n = +1$. ¿Es posible que
	la hipótesis que produce C sea mejor que la hipótesis que produce S? Justificar la respuesta.
\end{enumerate}

\answer

Puede suceder que la hipótesis producida por C sea mejor que la escogida por S. Para verlo más claro, siguiendo lo que
se nos ha dicho en el enunciado sobre los $y_n$ en $\mathcal{D}$, podemos suponer un caso extremo en el que las etiquetas
fuera de la muestra sean todas $y_n = -1$. En este caso, S escogería una hipótesis que funciona muy bien en la muestra,
ya que clasifica todos los datos bien, mientras que C sería pésimo y no clasificaría nada bien. Sin embargo, debido
a que la muestra no es lo suficientemente representativa de la población (de hecho, es una muy mala representación),
al intentar generalizar nos encontraríamos que S tiene un rendimiento pésimo ya que no clasificaría nada bien, 
mientras que C, al haber escogido la hipótesis en las que todas las etiquetas son $y_n = -1$ estaría acertando todos los
casos, siendo por tanto la hipótesis que tiene un rendimiento mejor fuera de la muestra de entrenamiento.


\section*{Ejercicio 6}
\addtoc{Ejercicio 6}

\noindent Considere la cota para la probabilidad de la hipótesis solución $g$ de un problema de aprendizaje, a partir de la
desigualdad generalizada de Hoeffding para una clase finita de hipótesis:

\[\mathbb{P}(  | \; \text{E}_{in}(g) - \text{E}_{out}(g) \; | \; > \varepsilon) < \delta \]

\begin{enumerate}[label=\textit{\alph*})]
	\item ¿Cuál es el algoritmo de aprendizaje que se usa para elegir $g$?
\end{enumerate}

\answer

El algoritmo de aprendizaje que se utiliza para elegir la función $g$ es indiferente, ya que este va a ir recorriendo el
conjunto de hipótesis $\mathcal{H}$ (las cuáles están prefijadas de antes) y escogerá una hipótesis final $g$, la cual
será la mejor de entre todas las hipótesis.

\begin{enumerate}[resume,label=\textit{\alph*})]
	\item Si elegimos $g$ de forma aleatoria ¿seguiría verificando la desigualdad?
\end{enumerate}

\answer

Aún habiendo escogido una función aleatoria como $g$, la desigualdad se seguiría cumpliendo, ya que la cota es aplicable
sobre cualquier hipótesis de la clase de funciones $\mathcal{H}$. Esta cota, $\delta$, viene dada por la siguiente expresión:

\[ \delta = 2 \; | \mathcal{H} | \; e^{-2 \varepsilon^2 N} \]

Como se puede ver, la cota no depende de la hipótesis final ($g$ no aparece en ningún lado de la expresión), si no que
depende de todas las hipótesis de $\mathcal{H}$, entre las cuales, eso sí, se encuentra $g$. Como $g$ se elige del
conjunto de hipótesis, si esta condición se cumple de forma genérica para cualquiera de las hipótesis, entonces también
se cumplirá para $g$, sea cuál sea la forma en la que se escoge.

\begin{enumerate}[resume,label=\textit{\alph*})]
	\item ¿Depende $g$ del algoritmo usado?
\end{enumerate}

\answer

La hipótesis final $g$ depende del algoritmo utlizado, ya que cada uno va a recorrer el conjunto de hipótesis de una forma
diferente. Por ejemplo, habrá algoritmos como el Gradiente Descendente que irán recorriendo iterativamente las hipótesis
hasta dar con una que sea buena. Otros, como las Ecuaciones Normales darán directamente con la solución al resolver un
sistema de ecuaciones.

\begin{enumerate}[resume,label=\textit{\alph*})]
	\item ¿Es una cota ajustada o una cota laxa?
\end{enumerate}

\answer

La cota es laxa (pesimista). Esta cota se obtiene suponiendo que si se da que la diferencia de errores con la 
hipótesis $g$ es mayor que un $\varepsilon$ dado es porque alguna de las hipótesis del conjunto tiene una diferencia de
errores superior a ese valor. La cota se obtiene mediante la desigualdad de Boole, ya que se supone que la probabilidad de la
unión de los eventos (que para alguna hipótesis la diferencia supere el valor de $\varepsilon$) es menor o igual que la
sumatoria de las probabilidades individuales, lo cuál resulta en la expresión
$2 \; | \mathcal{H} | \; e^{-2 \varepsilon^2 N}$. Este valor, sin embargo, tiene algunos problemas. Al acotar la unión de esta
forma se supone que todas las hipótesis son disjuntas; es decir, que no tienen una interesección, cuando en la realidad puede
ser que las hipótesis se solapen, y por tanto, el valor real de la unión de las probabilidades de los eventos sea mucho
menor que el de la sumatoria.


\section*{Ejercicio 7}
\addtoc{Ejercicio 7}

\noindent ¿Por qué la desigualdad de Hoeffding definida para clases $\mathcal{H}$ de una única función no es aplicable de
forma directa cuando el número de hipótesis de $\mathcal{H}$ es mayor de 1? Justificar la respuesta.

\answer

Como tal, la desigualdad de Hoeffding sigue siendo aplicable a cada función de la clase de forma individual, pero para 
aplicarla sobre el conjunto de funciones necesitamos algo más. 

Cada hipótesis $h_i \in \mathcal{H}$ se fija \textbf{antes} de generar el conjunto de datos,
y de entre todas las funciones de la clase, el algoritmo de aprendizaje escoge aquella función $g$ (hipótesis final)
que sea la mejor \textbf{una vez generados los datos}, no antes, haciendo imposible además modificar $h_i$, ya que si no, 
no se podría probar la desigualdad de Hoeffding.
Por tanto, como esa función $g$ es una de las $h_1, h_2, \dots, h_M$ funciones de la clase, queremos que la probabilidad
dada por:

\[ \mathbb{P}(\mathcal{D}: | \; \text{E}_{in}(h) - \text{E}_{out}(h) \; | \; > \varepsilon)\]

\noindent esté acotada por una expresión que tenga en cuenta todos los elementos de la clase $\mathcal{H}$
y no solo uno, que es lo que pasaba ahora. Con esto en mente, es necesario modificar la desigualdad de Hoeffding para
considerar la función $g$ escogida y que funcione para los casos en los que $|\mathcal{H}|$ sea mayor que 1 pero finito.

Para empezar, la expresión de la parte izquierda, una vez escogida la hipótesis final $g$, quedaría de la siguiente forma:

\begin{equation}
\label{eq:hoeffding_g}
	\mathbb{P}(\mathcal{D}: | \; \text{E}_{in}(g) - \text{E}_{out}(g) \; | \; > \varepsilon)
\end{equation}

Ahora lo que queremos hacer es encontrar una cota para la probabilidad de \eqref{eq:hoeffding_g} que tenga en cuenta todas
las posibles funciones de la clase, y que además no dependa de la $g$ escogida (puede ser cualquiera dentro de la clase).

Sabemos mediante la teoría de probabilidad que si ha sucedido que
$| \; \text{E}_{in}(g) - \text{E}_{out}(g) \; | \; > \varepsilon$ (evento $A$) es porque se ha dado que para alguna otra
función $h_i \in \mathcal{H}$, ha sucedido que $| \; \text{E}_{in}(h_i) - \text{E}_{out}(h_i) \; | \; > \varepsilon$
(evento $B$). Esto en probabilidad y en lógica se conoce como implicación, lo cuál se puede expresar como $A \Rightarrow B$.
Se sabe que si $A \Rightarrow B$ es que $\mathbb{P}(A) \leq \mathbb{P}(B)$.

Como queremos acotar la probabilidad de nuestro evento $A$, podemos utilizar la desigualdad de Boole, 
la cuál nos dice que para un conjunto finito de eventos, la probabilidad de que al menos uno suceda (en este caso, que algún
$\mathbb{P}(\mathcal{D}: | \; \text{E}_{in}(h_i) - \text{E}_{out}(h_i) \; | \; > \varepsilon)$) es menor o igual que la suma
de las probabilidades de los eventos (debido a que algunos eventos pueden no ser disjuntos). Dicho de otra forma:

\begin{equation}
\label{eq:union_bound}
\begin{split}
	\mathbb{P} \Bigg( \bigcup_{h_i \in \mathcal{H}}
	\mathbb{P}(\mathcal{D}: | \; \text{E}_{in}(h_i) - \text{E}_{out}(h_i) \; | \; > \varepsilon) \Bigg) &\leq
	\sum_{i = 1}^{|\mathcal{H}|} \mathbb{P}(\mathcal{D}: | \;\text{E}_{in}(h_i) - \text{E}_{out}(h_i) \; | \; > \varepsilon) \\
	&\leq 2 \; |\mathcal{H}|  \; e^{-2\varepsilon^2N}
\end{split}
\end{equation}

Así que, combinando las expresiones \eqref{eq:hoeffding_g} y \eqref{eq:union_bound}, obtenemos que:

\begin{equation}
	\mathbb{P}(\mathcal{D}: | \; \text{E}_{in}(g) - \text{E}_{out}(g) \; | \; > \varepsilon)  \leq
	2 \; |\mathcal{H}|  \; e^{-2\varepsilon^2N}
\end{equation}


Esta expresión ya sí que puede ser aplicada para clases con una o más hipótesis, siempre y cuando el número de éstas
sea finito, ya que se tiene en cuenta la cardinalidad de la clase de funciones $\mathcal{H}$.

\section*{Ejercicio 8}
\addtoc{Ejercicio 8}

\noindent Si queremos mostrar que $k$* es un punto de ruptura para una clase de funciones $\mathcal{H}$ cuáles de las
siguientes afirmaciones nos servirían para ello:

\begin{enumerate}[label=\textit{\alph*})]
	\item Mostrar que existe un conjunto de $k$* puntos $x_1, \dots, x_{k\text{*}}$ que $\mathcal{H}$ puede separar 
	(``shatter'').
\end{enumerate}

\answer

No nos sirve, ya que el punto de ruptura, por definición, es justamente un conjunto de puntos de tamaño $k$* que no puede
separar, y aquí se está planteando la situación contraria.

\begin{enumerate}[resume,label=\textit{\alph*})]
	\item Mostrar que $\mathcal{H}$ puede separar cualquier conjunto de $k$* puntos.
\end{enumerate}

\answer

De nuevo, esto tampoco nos sirve, ya que el punto de ruptura es para demostrar que hay un conjunto de puntos de tamaño
$k$* que $\mathcal{H}$ no puede separar. Si se intenta demostrar que se puede separar cualquier conjunto de $k$* puntos,
entonces se está haciendo justo lo contrario.

\begin{enumerate}[resume,label=\textit{\alph*})]
	\item Mostrar un conjunto de $k$* puntos  $x_1, \dots, x_{k\text{*}}$ que $\mathcal{H}$ no puede separar.
\end{enumerate}

\answer

De nuevo, tampoco nos serviría, ya que a lo mejor un conjunto de $k$* puntos no puede ser separado, pero existe otra
disposición de $k$* puntos (configurados de otra forma en el espacio) en el que se puedan conseguir todas las posibles
dicotomías, y por tanto, ese conjunto sería separable.

\begin{enumerate}[resume,label=\textit{\alph*})]
	\item Mostrar que $\mathcal{H}$ no puede separar ningún conjunto de $k$* puntos.
\end{enumerate}

\answer

Esto sí que nos serviría, ya que si se demuestra que ningún conjunto de $k$* puntos se puede separar (``shatter'') es
que en ninguna disposición de puntos se pueden separar las $2^{k\text{*}}$ posibles dicotomías, con lo cuál se obtiene
que para cualquier conjunto de $k$* puntos, $m_\mathcal{H}(k\text{*}) < 2^{k\text{*}}$.

\begin{enumerate}[resume,label=\textit{\alph*})]
	\item Mostrar que $m_\mathcal{H}(k) = 2^{k\text{*}}$.
\end{enumerate}

\answer

De nuevo, no nos serviría. Que $k$* sea un punto de ruptura no significa que, a partir de entonces, $\forall k > k$* 
el número máximo de dicotomías que se puedan separar satisfactoriamente sea $2^{k\text{*}}$, si no que el número máximo de
dicotomías separables viene dado por $m_\mathcal{H}(k) < 2^k$. Puede haber más de $2^{k\text{*}}$ dicotomías separables,
pero nunca $2^k$.

\section*{Ejercicio 9}
\addtoc{Ejercicio 9}

\noindent Para un conjunto $\mathcal{H}$ con $d_{VC} = 10$, ¿que tamaño muestral se necesita (según la cota de generalización)
para tener un 95\% de confianza ($\delta$) de que el error de generalización ($\varepsilon$) sea como mucho $0.05$?

\answer

Para obtener el tamaño de la muestra mínimo con la que se obtenga una buena generalización podemos calcular la complejidad
de la muestra, la cuál depende de $\varepsilon$ y $\delta$. La expresión es la siguiente:

\begin{equation}
\label{eq:sample_complexity}
	N \geq \frac{8}{\varepsilon^2} \ln \Bigg( \frac{4 \big( (2N)^{d_{\text{VC}}} + 1 \big)}{\delta} \Bigg)
\end{equation}

Ahora hay que fijar los valors de los parámetros, sabiendo que $\varepsilon = 0.05$, $\delta = 0.05$ y $d_{VC} = 10$. 
Como la resolución se tiene que ir haciendo de forma iterativa, se va a fijar que, inicialmente, $N = 1000$.

Antes de empezar con la resolución iterativa, vamos a tomar en cuenta algunas consideraciones.
Es importante destacar que la expresión de la parte izquierda resultante se va a redondear para evitar tener decimales. La
resolución se realizará escogiendo un $N$ e intentando ver si con ese valor se cumple la desigualdad. En caso de que se
cumpla, se parará. En caso contrario se escogerá como nuevo $N$ el valor obtenido en la parte derecha y se repetirá el cálculo.
Una vez dicho esto, veamos el proceso:

\[ 1000 \geq \frac{8}{0.05^2} \ln \Bigg( \frac{4 \big( (2 \cdot 1000)^{10} + 1 \big)}{0.05} \Bigg)
\Rightarrow 1000 \ngeq 257251 \]

\[ 257251 \geq \frac{8}{0.05^2} \ln \Bigg( \frac{4 \big( (2 \cdot 257251)^{10} + 1 \big)}{0.05} \Bigg)
\Rightarrow 257251 \ngeq 434853 \]

\[ 434853 \geq \frac{8}{0.05^2} \ln \Bigg( \frac{4 \big( (2 \cdot 434853)^{10} + 1 \big)}{0.05} \Bigg)
\Rightarrow 434853 \ngeq 451651 \]

\[ 451651 \geq \frac{8}{0.05^2} \ln \Bigg( \frac{4 \big( (2 \cdot 451651)^{10} + 1 \big)}{0.05} \Bigg)
\Rightarrow 451651 \ngeq 452864 \]

\[ 452864 \geq \frac{8}{0.05^2} \ln \Bigg( \frac{4 \big( (2 \cdot 452864)^{10} + 1 \big)}{0.05} \Bigg)
\Rightarrow 452864 \ngeq 452950 \]

\[ 452950 \geq \frac{8}{0.05^2} \ln \Bigg( \frac{4 \big( (2 \cdot 452950)^{10} + 1 \big)}{0.05} \Bigg)
\Rightarrow 452950 \ngeq 452956 \]

\[ 452956 \geq \frac{8}{0.05^2} \ln \Bigg( \frac{4 \big( (2 \cdot 452956)^{10} + 1 \big)}{0.05} \Bigg)
\Rightarrow 452956 \ngeq 452957 \]

\[ 452957 \geq \frac{8}{0.05^2} \ln \Bigg( \frac{4 \big( (2 \cdot 452957)^{10} + 1 \big)}{0.05} \Bigg)
\Rightarrow 452957 \geq 452957 \]

Con el resultado obtenido, podemos afirmar con un 95\% de confianza que con una muestra de tamaño $N = 452957$ tendremos
un error de generalización $\varepsilon$ que como mucho será 0.05.

\section*{Ejercicio 10}
\addtoc{Ejercicio 10}

\noindent Considere que le dan una nuestra de tamaño N de datos etiquetados $\lbrace -1, +1 \rbrace$ y le piden que
encuentre la función que mejor ajuste dichos datos. Dado que desconoce la verdadera función $f$, discuta los pros y 
contras de aplicar los principios de inducción ERM y SRM para lograr el objetivo. Valore las consecuencias de aplicar
cada uno de ellos.

\answer

Los \textbf{pros} de utilizar ERM es que, si tenemos una muestra lo suficientemente grande (tenemos más datos que el mínimo
necesario para generalizar bien, el cuál viene dado por la complejidad de la muestra) y la clase de funciones $\mathcal{H}$ es
finita (es decir, que el valor $d_{VC}$ es finito), entonces ERM permite obtener una buena hipótesis que generalice bien.
La \textbf{contra} es que, para que esto suceda, se tienen que dar las dos condiciones anteriores, ya que en caso de que por
ejemplo no se dé la primera, ERM no garantiza que se pueda llevar a cabo un aprendizaje correcto (es decir, que se consiga
el menor error posible fuera de la muestra), y en caso de que el valor $d_{VC}$ no sea finitio, no se puede aprender utilizando
ERM. Además, ERM de por sí, sin aplicar técnicas de regularización, no tiene forma de controlar el \textit{overfitting}, con lo
cuál, aunque se encuentre una hipótesis que explique perfectamente los puntos de la muestra de entrenamiento, puede que el
error fuera de la muestra sea muy elevado porque ha memorizado la muestra.

SRM, en cambio, es un criterio de aprendizaje más general que ERM. Algunos de los \textbf{pros} es que puede ser aplicado
por ejemplo cuando dada una clase de funciones $\mathcal{H}$, se dé que $d_{VC} = \infty$, ya que permite ir recorriendo las
subclases que la componen (las cuáles se sabe que tienen un valor $d_{VC}$ finito y más pequeño) y escoger una en la que el
error obtenido después de aplicar el criterio ERM para ésta junto con la penalización de esa subclase $\mathcal{H}_i$ sea la
mínima. Por tanto, con esto, se puede obtener la clase más simple que explique mejor los datos. Otro de ellos es que se puede
aplicar también cuando la clase de funciones tenga un valor $d_{VC}$ finito pero que el conjunto de datos sea demasiado pequeño
como para aplicar ERM, por los mismos motivos que antes. Además, SRM tiene la ventaja de que al elegir la subclase más simple
posible de entre las posibles, la probabilidad de que se produzca \textit{overfitting} es menor. Por \textbf{contra}, SMR
es más complejo de implementar, además de que se necesitan más recursos de tiempo y de cómputo para, en caso de encontrarnos
ante una clase de funciones con $d_{VC} = \infty$, encontrar la mejor subclase.

Por tanto, como una pequeña conclusión de cuál aplicar, si disponemos del número suficiente de datos, y el valor $d_{VC}$ de
la clase de funciones $\mathcal{H}$ es finito, podemos aplicar ERM, ya que nos permitirá obtener una muy buena hipótesis
en muy poco tiempo. En cambio, si la clase es infinita, o no disponemos de la cantidad suficiente de datos, deberíamos aplicar
SMR, con las correspondientes penalizaciones.


\newpage

\begin{thebibliography}{5}

\bibitem{boole-inequality}
Wikipedia. \textit{Desigualdad de Boole}
\\\url{https://en.wikipedia.org/wiki/Boole\%27s_inequality}

\bibitem{pac}
Wikipedia. \textit{Aprendizaje PAC}
\\\url{https://en.wikipedia.org/wiki/Probably_approximately_correct_learning}

\bibitem{SRM}
Structural Risk Minimization
\\\url{http://www.svms.org/srm/}

\bibitem{learning-from-data}
Yaser S. Abu-Mostafa, Malig Magdon-Ismail, Hsuan-Tien Lin. \textit{Learning From Data}. Capítulo 1: \textit{The Learning Problem.} Sección 1.3: \textit{Is Learning Feasible?} Páginas 22-24.

\end{thebibliography}

\end{document}

